{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca3a43a5-b7dd-4131-9ae3-48f5d275b7f0",
   "metadata": {},
   "source": [
    "# Document aligner project\n",
    "## NEW Model Implementation\n",
    "- U-Net backdone\n",
    "- Standard encoder-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9372fa8-a23f-423a-b62e-8ad6492b6aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_loader import get_dataloaders, visualize_batch\n",
    "from reconstruction_model import DocumentReconstructionModel\n",
    "from reconstruction_model import MaskedL1Loss, MaskedMSELoss, SSIMLoss, UVReconstructionLoss\n",
    "from training_val import train_one_epoch, validate\n",
    "\n",
    "import time \n",
    "import os\n",
    "import glob\n",
    "from typing import Dict, List, Tuple, Optional, Callable\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6389273-ed94-4d60-a5f7-f150ad3917cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2486 samples in /home/daniel-choate/Datasets/DocUnwarp/renders/synthetic_data_pitch_sweep\n",
      "Train samples: 1988, Val samples: 498\n"
     ]
    }
   ],
   "source": [
    "# Create dataloaders\n",
    "train_loader, val_loader = get_dataloaders(\n",
    "    data_dir='/home/daniel-choate/Datasets/DocUnwarp/renders/synthetic_data_pitch_sweep',\n",
    "    batch_size=8,\n",
    "    train_split=0.8,\n",
    "    img_size=(512, 512), #(256, 256)\n",
    ")\n",
    "\n",
    "# Visualize samples\n",
    "sample_batch = next(iter(train_loader))\n",
    "# visualize_batch(sample_batch, num_samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4803f3-313c-4604-898e-bf5b7d488fbe",
   "metadata": {},
   "source": [
    "# Model description\n",
    "- TODO\n",
    "\n",
    "Training:\n",
    "- [ ] Additional metrics (PSNR, SSIM)\n",
    "- [ ] Learning rate scheduling\n",
    "- [ ] Gradient clipping\n",
    "- [ ] Mixed precision training\n",
    "- [ ] Logging to tensorboard/wandb\n",
    "\n",
    "Main training loop\n",
    "- [ ] Implement better model architecture\n",
    "- [ ] Try different loss functions\n",
    "- [ ] Add learning rate scheduling\n",
    "- [ ] Implement early stopping\n",
    "- [ ] Add visualization and logging\n",
    "- [ ] Experiment with data augmentation\n",
    "- [ ] Use pretrained model from HuggingFace\n",
    "- [ ] Enable MASKED LOSSES\n",
    "- [ ] Use DEPTH\n",
    "- [ ] Use UV\n",
    "- [ ] Use BORDER\n",
    "- [ ] Try different OPTIMIZERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368f2c8e-f271-43ab-bae7-762268d4b58b",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e41ba305-0351-4b61-b3e4-75c4b9e7f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop \n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main training loop \n",
    "\n",
    "    *** CHECK TODO LIST ***\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configuration\n",
    "    DATA_DIR = '/home/daniel-choate/Datasets/DocUnwarp/renders/synthetic_data_pitch_sweep'\n",
    "    BATCH_SIZE = 8\n",
    "    NUM_EPOCHS = 50\n",
    "    LEARNING_RATE = 1e-4\n",
    "    IMG_SIZE = (256, 256) # (512, 512) Using smaller images for faster training for now\n",
    "\n",
    "    # Set device \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader, val_loader = get_dataloaders(\n",
    "        data_dir=DATA_DIR,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        img_size=IMG_SIZE,\n",
    "        use_depth=False, # TODO: True if using depth info\n",
    "        use_uv=False, # TODO: True if using UV maps\n",
    "        use_border=False # TODO: True if using border masks for better training\n",
    "    )\n",
    "\n",
    "    # Visualize a batch (testing)\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    print(f\"Batch RGB shape: {sample_batch['rgb'].shape}\")\n",
    "    print(f\"Batch GT shape: {sample_batch['ground_truth'].shape}\")\n",
    "    if 'border' in sample_batch:\n",
    "        print(f\"Batch border mask shape: {sample_batch['border'].shape}\")\n",
    "    # visualize_batch(sample_batch) # Troubleshooting / sanity check \n",
    "\n",
    "\n",
    "    # Create model\n",
    "    model = DocumentReconstructionModel().to(device)\n",
    "    print(f\"\\nModel parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "    # TODO: TRY DIFFERENT LOSS FUNCTIONS\n",
    "    # Option 1: simple losses (baseline, just to get it working)\n",
    "    # criterion = nn.MSELoss() # Basic L2 Loss - sensitive to lighting\n",
    "    # criterion = nn.L1Loss() # L1 loss also sensitive to lighting\n",
    "\n",
    "    # Option 2: SSIM loss (RECOMMENDED - structure instead of lighting)\n",
    "    criterion = SSIMLoss() # Might need a pip install\n",
    "\n",
    "    # Option 3: Masked losses (doc pixel focus)\n",
    "    # Make sure to do use_border = True above **\n",
    "    # criterion = MaskedL1Loss(use_mask=True)\n",
    "    # criterion = MaskedMSELoss(use_mask=True)\n",
    "\n",
    "    # Option 4: Combined loss with UV supervision (GET TO THIS EVENTUALLY)\n",
    "    # NOTE: need to set use_uv = True, use_border = True, \n",
    "    # criterion = UVReconstructionLoss(\n",
    "    #     reconstruction_weight=1.0,\n",
    "    #     uv_weight=0.5,\n",
    "    #     smoothness_weight=0.01, \n",
    "    #     use_mask=True,\n",
    "    #     loss_type='ssim' # Use SSIM for geometric recon\n",
    "    # )\n",
    "\n",
    "    # TODO: TRY DIFFERENT OPTIMIZERS\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "\n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # Epoch timing check\n",
    "        start_epoch = time.time()\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"EPOCH {epoch+1}/{NUM_EPOCHS}\")\n",
    "        print(f\"{'='*50}\")\n",
    "\n",
    "        # TRAIN \n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "        print(f\"Train loss: {train_loss:.4f}\")\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # VALIDATE \n",
    "        val_loss = validate(model, val_loader, criterion, device)\n",
    "        print(f\"Val Loss: {val_loss:.4f}\")\n",
    "        val_losses.append(val_loss)\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses\n",
    "        }, 'training_history.pth')\n",
    "\n",
    "        # Save the best model \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f\"Saved best model with val loss {val_loss:.4f}\")\n",
    "\n",
    "        epoch_time = time.time() - start_epoch\n",
    "        print(f\"Epoch time: {epoch_time:.4f}s\")\n",
    "\n",
    "    print(\"\\nTraining complete!\")\n",
    "    print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "    # Loss curve \n",
    "    epochs = range(1, NUM_EPOCHS + 1)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(epochs, train_losses, label='Train Loss')\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training & Validation Loss Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96cee6e9-4750-42eb-985b-db6e41b1bdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Reconstruction Dataset Loader\n",
      "==================================================\n",
      "Found 2486 samples in /home/daniel-choate/Datasets/DocUnwarp/renders/synthetic_data_pitch_sweep\n",
      "Train samples: 1988, Val samples: 498\n",
      "\n",
      "Dataset loaded successfully!\n",
      "Using device: cuda\n",
      "Found 2486 samples in /home/daniel-choate/Datasets/DocUnwarp/renders/synthetic_data_pitch_sweep\n",
      "Train samples: 1988, Val samples: 498\n",
      "Batch RGB shape: torch.Size([8, 3, 256, 256])\n",
      "Batch GT shape: torch.Size([8, 3, 256, 256])\n",
      "\n",
      "Model parameters: 7,698,434\n",
      "\n",
      "==================================================\n",
      "EPOCH 1/50\n",
      "==================================================\n",
      "Train loss: 0.9777\n",
      "Val Loss: 0.9660\n",
      "Saved best model with val loss 0.9660\n",
      "Epoch time: 79.7451s\n",
      "\n",
      "==================================================\n",
      "EPOCH 2/50\n",
      "==================================================\n",
      "Train loss: 0.9601\n",
      "Val Loss: 0.9537\n",
      "Saved best model with val loss 0.9537\n",
      "Epoch time: 80.3549s\n",
      "\n",
      "==================================================\n",
      "EPOCH 3/50\n",
      "==================================================\n",
      "Train loss: 0.9398\n",
      "Val Loss: 0.9192\n",
      "Saved best model with val loss 0.9192\n",
      "Epoch time: 79.9185s\n",
      "\n",
      "==================================================\n",
      "EPOCH 4/50\n",
      "==================================================\n",
      "Train loss: 0.8954\n",
      "Val Loss: 0.8659\n",
      "Saved best model with val loss 0.8659\n",
      "Epoch time: 79.1365s\n",
      "\n",
      "==================================================\n",
      "EPOCH 5/50\n",
      "==================================================\n",
      "Train loss: 0.8597\n",
      "Val Loss: 0.8551\n",
      "Saved best model with val loss 0.8551\n",
      "Epoch time: 79.0766s\n",
      "\n",
      "==================================================\n",
      "EPOCH 6/50\n",
      "==================================================\n",
      "Train loss: 0.8456\n",
      "Val Loss: 0.8333\n",
      "Saved best model with val loss 0.8333\n",
      "Epoch time: 78.9592s\n",
      "\n",
      "==================================================\n",
      "EPOCH 7/50\n",
      "==================================================\n",
      "Train loss: 0.8349\n",
      "Val Loss: 0.8305\n",
      "Saved best model with val loss 0.8305\n",
      "Epoch time: 78.9493s\n",
      "\n",
      "==================================================\n",
      "EPOCH 8/50\n",
      "==================================================\n",
      "Train loss: 0.8289\n",
      "Val Loss: 0.8369\n",
      "Epoch time: 78.7375s\n",
      "\n",
      "==================================================\n",
      "EPOCH 9/50\n",
      "==================================================\n",
      "Train loss: 0.8252\n",
      "Val Loss: 0.8206\n",
      "Saved best model with val loss 0.8206\n",
      "Epoch time: 78.7825s\n",
      "\n",
      "==================================================\n",
      "EPOCH 10/50\n",
      "==================================================\n",
      "Train loss: 0.8191\n",
      "Val Loss: 0.8230\n",
      "Epoch time: 78.7365s\n",
      "\n",
      "==================================================\n",
      "EPOCH 11/50\n",
      "==================================================\n",
      "Train loss: 0.8167\n",
      "Val Loss: 0.8135\n",
      "Saved best model with val loss 0.8135\n",
      "Epoch time: 79.0145s\n",
      "\n",
      "==================================================\n",
      "EPOCH 12/50\n",
      "==================================================\n",
      "Train loss: 0.8129\n",
      "Val Loss: 0.8085\n",
      "Saved best model with val loss 0.8085\n",
      "Epoch time: 78.8339s\n",
      "\n",
      "==================================================\n",
      "EPOCH 13/50\n",
      "==================================================\n",
      "Train loss: 0.8102\n",
      "Val Loss: 0.8032\n",
      "Saved best model with val loss 0.8032\n",
      "Epoch time: 78.8130s\n",
      "\n",
      "==================================================\n",
      "EPOCH 14/50\n",
      "==================================================\n",
      "Train loss: 0.8090\n",
      "Val Loss: 0.8142\n",
      "Epoch time: 78.7091s\n",
      "\n",
      "==================================================\n",
      "EPOCH 15/50\n",
      "==================================================\n",
      "Train loss: 0.8076\n",
      "Val Loss: 0.8018\n",
      "Saved best model with val loss 0.8018\n",
      "Epoch time: 78.7186s\n",
      "\n",
      "==================================================\n",
      "EPOCH 16/50\n",
      "==================================================\n",
      "Train loss: 0.8041\n",
      "Val Loss: 0.7986\n",
      "Saved best model with val loss 0.7986\n",
      "Epoch time: 78.8108s\n",
      "\n",
      "==================================================\n",
      "EPOCH 17/50\n",
      "==================================================\n",
      "Train loss: 0.8036\n",
      "Val Loss: 0.7990\n",
      "Epoch time: 78.6321s\n",
      "\n",
      "==================================================\n",
      "EPOCH 18/50\n",
      "==================================================\n",
      "Train loss: 0.8030\n",
      "Val Loss: 0.7949\n",
      "Saved best model with val loss 0.7949\n",
      "Epoch time: 78.7414s\n",
      "\n",
      "==================================================\n",
      "EPOCH 19/50\n",
      "==================================================\n",
      "Train loss: 0.8011\n",
      "Val Loss: 0.7999\n",
      "Epoch time: 78.6224s\n",
      "\n",
      "==================================================\n",
      "EPOCH 20/50\n",
      "==================================================\n",
      "Train loss: 0.8006\n",
      "Val Loss: 0.7997\n",
      "Epoch time: 78.9921s\n",
      "\n",
      "==================================================\n",
      "EPOCH 21/50\n",
      "==================================================\n",
      "Train loss: 0.7992\n",
      "Val Loss: 0.7973\n",
      "Epoch time: 79.1981s\n",
      "\n",
      "==================================================\n",
      "EPOCH 22/50\n",
      "==================================================\n",
      "Train loss: 0.7973\n",
      "Val Loss: 0.7930\n",
      "Saved best model with val loss 0.7930\n",
      "Epoch time: 79.1750s\n",
      "\n",
      "==================================================\n",
      "EPOCH 23/50\n",
      "==================================================\n",
      "Train loss: 0.7956\n",
      "Val Loss: 0.7954\n",
      "Epoch time: 79.1427s\n",
      "\n",
      "==================================================\n",
      "EPOCH 24/50\n",
      "==================================================\n",
      "Train loss: 0.7957\n",
      "Val Loss: 0.7879\n",
      "Saved best model with val loss 0.7879\n",
      "Epoch time: 79.1904s\n",
      "\n",
      "==================================================\n",
      "EPOCH 25/50\n",
      "==================================================\n",
      "Train loss: 0.7936\n",
      "Val Loss: 0.7887\n",
      "Epoch time: 79.2737s\n",
      "\n",
      "==================================================\n",
      "EPOCH 26/50\n",
      "==================================================\n",
      "Train loss: 0.7927\n",
      "Val Loss: 0.7876\n",
      "Saved best model with val loss 0.7876\n",
      "Epoch time: 79.1794s\n",
      "\n",
      "==================================================\n",
      "EPOCH 27/50\n",
      "==================================================\n",
      "Train loss: 0.7922\n",
      "Val Loss: 0.7887\n",
      "Epoch time: 79.2857s\n",
      "\n",
      "==================================================\n",
      "EPOCH 28/50\n",
      "==================================================\n",
      "Train loss: 0.7913\n",
      "Val Loss: 0.7893\n",
      "Epoch time: 79.2106s\n",
      "\n",
      "==================================================\n",
      "EPOCH 29/50\n",
      "==================================================\n",
      "Train loss: 0.7918\n",
      "Val Loss: 0.7862\n",
      "Saved best model with val loss 0.7862\n",
      "Epoch time: 79.4329s\n",
      "\n",
      "==================================================\n",
      "EPOCH 30/50\n",
      "==================================================\n",
      "Train loss: 0.7908\n",
      "Val Loss: 0.7865\n",
      "Epoch time: 79.2978s\n",
      "\n",
      "==================================================\n",
      "EPOCH 31/50\n",
      "==================================================\n",
      "Train loss: 0.7907\n",
      "Val Loss: 0.7815\n",
      "Saved best model with val loss 0.7815\n",
      "Epoch time: 79.3133s\n",
      "\n",
      "==================================================\n",
      "EPOCH 32/50\n",
      "==================================================\n",
      "Train loss: 0.7883\n",
      "Val Loss: 0.7830\n",
      "Epoch time: 79.2911s\n",
      "\n",
      "==================================================\n",
      "EPOCH 33/50\n",
      "==================================================\n",
      "Train loss: 0.7876\n",
      "Val Loss: 0.7843\n",
      "Epoch time: 79.2683s\n",
      "\n",
      "==================================================\n",
      "EPOCH 34/50\n",
      "==================================================\n",
      "Train loss: 0.7878\n",
      "Val Loss: 0.7846\n",
      "Epoch time: 79.2543s\n",
      "\n",
      "==================================================\n",
      "EPOCH 35/50\n",
      "==================================================\n",
      "Train loss: 0.7880\n",
      "Val Loss: 0.7889\n",
      "Epoch time: 79.2238s\n",
      "\n",
      "==================================================\n",
      "EPOCH 36/50\n",
      "==================================================\n",
      "Train loss: 0.7864\n",
      "Val Loss: 0.7817\n",
      "Epoch time: 78.9981s\n",
      "\n",
      "==================================================\n",
      "EPOCH 37/50\n",
      "==================================================\n",
      "Train loss: 0.7869\n",
      "Val Loss: 0.7829\n",
      "Epoch time: 79.2909s\n",
      "\n",
      "==================================================\n",
      "EPOCH 38/50\n",
      "==================================================\n",
      "Train loss: 0.7865\n",
      "Val Loss: 0.7885\n",
      "Epoch time: 79.1759s\n",
      "\n",
      "==================================================\n",
      "EPOCH 39/50\n",
      "==================================================\n",
      "Train loss: 0.7873\n",
      "Val Loss: 0.7797\n",
      "Saved best model with val loss 0.7797\n",
      "Epoch time: 79.2724s\n",
      "\n",
      "==================================================\n",
      "EPOCH 40/50\n",
      "==================================================\n",
      "Train loss: 0.7861\n",
      "Val Loss: 0.7865\n",
      "Epoch time: 79.3046s\n",
      "\n",
      "==================================================\n",
      "EPOCH 41/50\n",
      "==================================================\n",
      "Train loss: 0.7858\n",
      "Val Loss: 0.7790\n",
      "Saved best model with val loss 0.7790\n",
      "Epoch time: 79.3449s\n",
      "\n",
      "==================================================\n",
      "EPOCH 42/50\n",
      "==================================================\n",
      "Train loss: 0.7845\n",
      "Val Loss: 0.7799\n",
      "Epoch time: 79.2745s\n",
      "\n",
      "==================================================\n",
      "EPOCH 43/50\n",
      "==================================================\n",
      "Train loss: 0.7852\n",
      "Val Loss: 0.7798\n",
      "Epoch time: 79.3173s\n",
      "\n",
      "==================================================\n",
      "EPOCH 44/50\n",
      "==================================================\n",
      "Train loss: 0.7824\n",
      "Val Loss: 0.7794\n",
      "Epoch time: 79.2946s\n",
      "\n",
      "==================================================\n",
      "EPOCH 45/50\n",
      "==================================================\n",
      "Train loss: 0.7827\n",
      "Val Loss: 0.7786\n",
      "Saved best model with val loss 0.7786\n",
      "Epoch time: 79.1615s\n",
      "\n",
      "==================================================\n",
      "EPOCH 46/50\n",
      "==================================================\n",
      "Train loss: 0.7828\n",
      "Val Loss: 0.7783\n",
      "Saved best model with val loss 0.7783\n",
      "Epoch time: 79.5050s\n",
      "\n",
      "==================================================\n",
      "EPOCH 47/50\n",
      "==================================================\n",
      "Train loss: 0.7834\n",
      "Val Loss: 0.7791\n",
      "Epoch time: 79.3062s\n",
      "\n",
      "==================================================\n",
      "EPOCH 48/50\n",
      "==================================================\n",
      "Train loss: 0.7808\n",
      "Val Loss: 0.7773\n",
      "Saved best model with val loss 0.7773\n",
      "Epoch time: 79.4432s\n",
      "\n",
      "==================================================\n",
      "EPOCH 49/50\n",
      "==================================================\n",
      "Train loss: 0.7816\n",
      "Val Loss: 0.7767\n",
      "Saved best model with val loss 0.7767\n",
      "Epoch time: 79.2887s\n",
      "\n",
      "==================================================\n",
      "EPOCH 50/50\n",
      "==================================================\n",
      "Train loss: 0.7819\n",
      "Val Loss: 0.7801\n",
      "Epoch time: 79.2842s\n",
      "\n",
      "Training complete!\n",
      "Best validation loss: 0.7767\n"
     ]
    }
   ],
   "source": [
    "# Execute main \n",
    "\n",
    "print(\"Document Reconstruction Dataset Loader\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Quick test \n",
    "train_loader, val_loader = get_dataloaders(\n",
    "    data_dir = '/home/daniel-choate/Datasets/DocUnwarp/renders/synthetic_data_pitch_sweep',\n",
    "    batch_size = 4, \n",
    "    img_size=(256, 256) # (512,512)\n",
    ")\n",
    "\n",
    "print(\"\\nDataset loaded successfully!\")\n",
    "\n",
    "# # Visualize sample batch \n",
    "# print(\"\\nVisualizing a sample batch ...\")\n",
    "# sample_batch = next(iter(train_loader))\n",
    "# print(f\"Batch shape - RGB: {sample_batch['rgb'].shape}, Ground Truth: {sample_batch['ground_truth'].shape}\")\n",
    "# visualize_batch(sample_batch, num_samples=min(4, sample_batch['rgb'].shape[0]))\n",
    "\n",
    "# Main training loop \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ccc8acc-ec19-4ef2-bfdd-67efee5dfc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_84480/1360197661.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  history = torch.load('training_history.pth')\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'training_history.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Loss plot \u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining_history.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_losses\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m val_losses \u001b[38;5;241m=\u001b[39m history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_losses\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/cvf25/lib/python3.9/site-packages/torch/serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/miniconda3/envs/cvf25/lib/python3.9/site-packages/torch/serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/miniconda3/envs/cvf25/lib/python3.9/site-packages/torch/serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'training_history.pth'"
     ]
    }
   ],
   "source": [
    "# Loss plot \n",
    "\n",
    "\n",
    "history = torch.load('training_history.pth')\n",
    "\n",
    "train_losses = history['train_losses']\n",
    "val_losses = history['val_losses']\n",
    "epochs = range(1, 50 + 1)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, train_losses, label='Train Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066e6e1-6104-47da-bbcb-fd7f67166c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6728a9b3-eab3-439d-ac7e-79e8efc56788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
