{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca3a43a5-b7dd-4131-9ae3-48f5d275b7f0",
   "metadata": {},
   "source": [
    "# Document aligner project\n",
    "## NEW Model Implementation\n",
    "### LAST ITERATION BEFORE FINAL \n",
    "- U-Net with skip connections\n",
    "- Flow predictor, differentiable warping\n",
    "- Standard encoder-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9372fa8-a23f-423a-b62e-8ad6492b6aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_loader import get_dataloaders, visualize_batch, visualize_flow_and_warp, visualize_batch_pred\n",
    "from reconstruction_model import ResNetUnet\n",
    "from reconstruction_model import MaskedL1Loss, MaskedMSELoss, SSIMLoss, UVReconstructionLoss\n",
    "from training_val import train_one_epoch, validate\n",
    "\n",
    "import time \n",
    "import os\n",
    "import glob\n",
    "from typing import Dict, List, Tuple, Optional, Callable\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6389273-ed94-4d60-a5f7-f150ad3917cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_loader, val_loader = get_dataloaders(\n",
    "    data_dir='/home/daniel-choate/Datasets/DocUnwarp/renders/synthetic_data_pitch_sweep',\n",
    "    batch_size=8,\n",
    "    train_split=0.8,\n",
    "    img_size=(512, 512), #(256, 256)\n",
    ")\n",
    "\n",
    "# Visualize samples\n",
    "sample_batch = next(iter(train_loader))\n",
    "# visualize_batch(sample_batch, num_samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4803f3-313c-4604-898e-bf5b7d488fbe",
   "metadata": {},
   "source": [
    "# Model description\n",
    "- TODO\n",
    "\n",
    "Training:\n",
    "- [x] Additional metrics (PSNR, SSIM)\n",
    "- [x] Learning rate scheduling\n",
    "- [ ] Gradient clipping\n",
    "- [ ] Mixed precision training\n",
    "- [ ] Logging to tensorboard/wandb\n",
    "\n",
    "Main training loop\n",
    "- [x] Implement better model architecture\n",
    "- [x] Try different loss functions\n",
    "- [x] Add learning rate scheduling\n",
    "- [ ] Implement early stopping\n",
    "- [ ] Add visualization and logging\n",
    "- [ ] Experiment with data augmentation\n",
    "- [ ] Use pretrained model from HuggingFace\n",
    "- [ ] Enable MASKED LOSSES\n",
    "- [ ] Use DEPTH\n",
    "- [x] Use UV\n",
    "- [x] Use BORDER\n",
    "- [x] Try different OPTIMIZERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368f2c8e-f271-43ab-bae7-762268d4b58b",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41ba305-0351-4b61-b3e4-75c4b9e7f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop \n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main training loop \n",
    "\n",
    "    *** CHECK TODO LIST ***\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configuration\n",
    "    DATA_DIR = '/home/daniel-choate/Datasets/DocUnwarp/renders/synthetic_data_pitch_sweep'\n",
    "    BATCH_SIZE = 8\n",
    "    NUM_EPOCHS = 50\n",
    "    LEARNING_RATE = 1e-4\n",
    "    IMG_SIZE = (256, 256) # (512, 512) Using smaller images for faster training for now\n",
    "\n",
    "    # Set device \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader, val_loader = get_dataloaders(\n",
    "        data_dir=DATA_DIR,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        img_size=IMG_SIZE,\n",
    "        use_depth=False, # TODO: True if using depth info\n",
    "        use_uv=True, # TODO: True if using UV maps\n",
    "        use_border=True # TODO: True if using border masks for better training\n",
    "    )\n",
    "\n",
    "    # Create model\n",
    "    # model = DocumentReconstructionModel().to(device)\n",
    "    model = ResNetUnet(\n",
    "        backbone_name='resnet34',\n",
    "        pretrained=True\n",
    "    ).to(device)\n",
    "    print(f\"\\nModel parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # Visualize a batch (testing)\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    print(f\"Batch RGB shape: {sample_batch['rgb'].shape}\")\n",
    "    print(f\"Batch GT shape: {sample_batch['ground_truth'].shape}\")\n",
    "    if 'border' in sample_batch:\n",
    "        print(f\"Batch border mask shape: {sample_batch['border'].shape}\")\n",
    "    if 'uv' in sample_batch:\n",
    "        print(f\"Batch UV shape: {sample_batch['uv'].shape}\")\n",
    "    # visualize_batch(sample_batch)  # Optional visualization\n",
    "    visualize_flow_and_warp(model, sample_batch, device, num_samples=4)\n",
    "\n",
    "\n",
    "    # TODO: TRY DIFFERENT LOSS FUNCTIONS\n",
    "    # Option 1: simple losses (baseline, just to get it working)\n",
    "    # criterion = nn.MSELoss() # Basic L2 Loss - sensitive to lighting\n",
    "    # criterion = nn.L1Loss() # L1 loss also sensitive to lighting\n",
    "\n",
    "    # Option 2: SSIM loss (RECOMMENDED - structure instead of lighting)\n",
    "    # criterion = SSIMLoss() # Might need a pip install\n",
    "\n",
    "    # Option 3: Masked losses (doc pixel focus)\n",
    "    # Make sure to do use_border = True above **\n",
    "    # criterion = MaskedL1Loss(use_mask=True)\n",
    "    # criterion = MaskedMSELoss(use_mask=True)\n",
    "\n",
    "    # Option 4: Combined loss with UV supervision (GET TO THIS EVENTUALLY)\n",
    "    # NOTE: need to set use_uv = True, use_border = True, \n",
    "    criterion = UVReconstructionLoss(\n",
    "        reconstruction_weight=1.0,\n",
    "        uv_weight=0.0, # Turning off for now \n",
    "        smoothness_weight=0.01, \n",
    "        use_mask=True,\n",
    "        loss_type='ssim' # Use SSIM for geometric recon\n",
    "    )\n",
    "\n",
    "    # TODO: TRY DIFFERENT OPTIMIZERS\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "\n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # Epoch timing check\n",
    "        start_epoch = time.time()\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"EPOCH {epoch+1}/{NUM_EPOCHS}\")\n",
    "        print(f\"{'='*50}\")\n",
    "\n",
    "        # TRAIN \n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "        print(f\"Train loss: {train_loss:.4f}\")\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # VALIDATE \n",
    "        val_loss = validate(model, val_loader, criterion, device)\n",
    "        print(f\"Val Loss: {val_loss:.4f}\")\n",
    "        val_losses.append(val_loss)\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses\n",
    "        }, 'training_history.pth')\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                sample_batch = next(iter(val_loader))\n",
    "\n",
    "                \n",
    "                rgb = sample_batch['rgb'].to(device)\n",
    "                outputs = model(rgb, predict_uv=False)\n",
    "\n",
    "\n",
    "                # # MASK SANITY CHECK\n",
    "                # rgb_single = sample_batch['rgb'][0].cpu()       # [3, H, W]\n",
    "                # border_single = sample_batch['border'][0].cpu() # [1, H, W]\n",
    "\n",
    "                # mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
    "                # std  = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n",
    "                # rgb_vis = torch.clamp(rgb_single * std + mean, 0, 1)  # [3, H, W]\n",
    "\n",
    "                # rgb_np  = rgb_vis.permute(1,2,0).numpy()              # [H, W, 3]\n",
    "                # mask_np = border_single.squeeze(0).numpy()            # [H, W]\n",
    "\n",
    "                # plt.figure(figsize=(12,4))\n",
    "                # plt.subplot(1,3,1); plt.imshow(rgb_np); plt.title(\"RGB\"); plt.axis(\"off\")\n",
    "                # plt.subplot(1,3,2); plt.imshow(mask_np, cmap=\"gray\"); plt.title(\"Raw mask\"); plt.axis(\"off\")\n",
    "                # plt.subplot(1,3,3); plt.imshow(rgb_np); plt.imshow(mask_np, cmap=\"jet\", alpha=0.3); plt.title(\"Overlay\"); plt.axis(\"off\")\n",
    "                # plt.show()\n",
    "\n",
    "                batch_vis = {\n",
    "                    'rgb': sample_batch['rgb'],\n",
    "                    'ground_truth': sample_batch['ground_truth'],\n",
    "                    'predicted': outputs['warped'].cpu()\n",
    "                }\n",
    "    \n",
    "                print(f\"\\n[Visualization] Epoch {epoch+1}\")\n",
    "                visualize_batch_pred(batch_vis, num_samples=4)\n",
    "                visualize_flow_and_warp(model, sample_batch, device, num_samples=4)\n",
    "\n",
    "        # Save the best model \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f\"Saved best model with val loss {val_loss:.4f}\")\n",
    "\n",
    "        epoch_time = time.time() - start_epoch\n",
    "        print(f\"Epoch time: {epoch_time:.4f}s\")\n",
    "\n",
    "    print(\"\\nTraining complete!\")\n",
    "    print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "    # Loss curve \n",
    "    epochs = range(1, NUM_EPOCHS + 1)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(epochs, train_losses, label='Train Loss')\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training & Validation Loss Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cee6e9-4750-42eb-985b-db6e41b1bdff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Execute main \n",
    "\n",
    "print(\"Document Reconstruction Dataset Loader\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Quick test \n",
    "train_loader, val_loader = get_dataloaders(\n",
    "    data_dir = '/home/daniel-choate/Datasets/DocUnwarp/renders/synthetic_data_pitch_sweep',\n",
    "    batch_size = 4, \n",
    "    img_size=(256, 256) # (512,512)\n",
    ")\n",
    "\n",
    "print(\"\\nDataset loaded successfully!\")\n",
    "\n",
    "# # Visualize sample batch \n",
    "# print(\"\\nVisualizing a sample batch ...\")\n",
    "# sample_batch = next(iter(train_loader))\n",
    "# print(f\"Batch shape - RGB: {sample_batch['rgb'].shape}, Ground Truth: {sample_batch['ground_truth'].shape}\")\n",
    "# visualize_batch(sample_batch, num_samples=min(4, sample_batch['rgb'].shape[0]))\n",
    "\n",
    "# Main training loop \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc8acc-ec19-4ef2-bfdd-67efee5dfc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss plot \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history = torch.load('training_history.pth')\n",
    "\n",
    "train_losses = history['train_losses']\n",
    "val_losses = history['val_losses']\n",
    "epochs = range(1, 31 + 1)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, train_losses, label='Train Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066e6e1-6104-47da-bbcb-fd7f67166c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6728a9b3-eab3-439d-ac7e-79e8efc56788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
