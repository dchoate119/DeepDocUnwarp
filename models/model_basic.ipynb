{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca3a43a5-b7dd-4131-9ae3-48f5d275b7f0",
   "metadata": {},
   "source": [
    "# Document aligner project\n",
    "## Basic Model Implementation\n",
    "- Working on milestone 1\n",
    "- Implementing a simple encoder decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9372fa8-a23f-423a-b62e-8ad6492b6aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_loader import get_dataloaders, visualize_batch\n",
    "from reconstruction_model import DocumentReconstructionModel\n",
    "from reconstruction_model import MaskedL1Loss, MaskedMSELoss, SSIMLoss, UVReconstructionLoss\n",
    "\n",
    "import time \n",
    "import os\n",
    "import glob\n",
    "from typing import Dict, List, Tuple, Optional, Callable\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6389273-ed94-4d60-a5f7-f150ad3917cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_loader, val_loader = get_dataloaders(\n",
    "    data_dir='/home/daniel-choate/Datasets/DocUnwarp/renders/synthetic_data_pitch_sweep',\n",
    "    batch_size=8,\n",
    "    train_split=0.8,\n",
    "    img_size=(512, 512), #(256, 256)\n",
    ")\n",
    "\n",
    "# Visualize samples\n",
    "sample_batch = next(iter(train_loader))\n",
    "# visualize_batch(sample_batch, num_samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4803f3-313c-4604-898e-bf5b7d488fbe",
   "metadata": {},
   "source": [
    "# Model description\n",
    "- TODO\n",
    "\n",
    "Training:\n",
    "- [ ] Additional metrics (PSNR, SSIM)\n",
    "- [ ] Learning rate scheduling\n",
    "- [ ] Gradient clipping\n",
    "- [ ] Mixed precision training\n",
    "- [ ] Logging to tensorboard/wandb\n",
    "\n",
    "Main training loop\n",
    "- [ ] Implement better model architecture\n",
    "- [ ] Try different loss functions\n",
    "- [ ] Add learning rate scheduling\n",
    "- [ ] Implement early stopping\n",
    "- [ ] Add visualization and logging\n",
    "- [ ] Experiment with data augmentation\n",
    "- [ ] Use pretrained model from HuggingFace\n",
    "- [ ] Enable MASKED LOSSES\n",
    "- [ ] Use DEPTH\n",
    "- [ ] Use UV\n",
    "- [ ] Use BORDER\n",
    "- [ ] Try different OPTIMIZERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9805747-11b3-42f3-96a5-8774e408a8e9",
   "metadata": {},
   "source": [
    "## Training and validation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2004eaa2-e376-4dad-aef7-2742f4375bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop \n",
    "\n",
    "def train_one_epoch(\n",
    "    model: nn.Module, \n",
    "    dataloader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer, \n",
    "    device: torch.device, \n",
    "    epoch: int\n",
    ") -> float:\n",
    "    \"\"\" \n",
    "    Train for one epoch\n",
    "\n",
    "    *** CHECK TODO LIST ***\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Loop through each batch \n",
    "    # t_batch_start = time.time()\n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        t0 = time.time() # TIMING CHECK 0\n",
    "        # print(f\"DataLoader prep time: {(t0 - t_batch_start)*1000:.1f}ms\")\n",
    "        # Move data to device \n",
    "        rgb = batch['rgb'].to(device)\n",
    "        ground_truth = batch['ground_truth'].to(device)\n",
    "\n",
    "        # Load mask if using masked loss\n",
    "        mask = batch.get('border', None)\n",
    "        if mask is not None:\n",
    "            mask = mask.to(device)\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        t1 = time.time() # TIMING CHECK 1\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(rgb)\n",
    "        # print(f\"Finished batch {batch_idx}\")\n",
    "\n",
    "        # Compute loss\n",
    "        if isinstance(criterion, (MaskedL1Loss, MaskedMSELoss)):\n",
    "            loss = criterion(output, ground_truth, mask)\n",
    "        elif isinstance(criterion, SSIMLoss):\n",
    "            loss = criterion(output, ground_truth)\n",
    "        elif isinstance(criterion, UVReconstructionLoss):\n",
    "            # Extract additional outputs if avail for UV-based\n",
    "            losses=criterion(pred_image=output, target_image=ground_truth, mask=mask)\n",
    "            loss=losses['total']\n",
    "        else:\n",
    "            # Standard (MSE, L1)\n",
    "            # print(f\"Standard loss: {criterion}\")\n",
    "            loss = criterion(output, ground_truth)\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        t2 = time.time() # TIMING CHECK 2\n",
    "\n",
    "        # Backward pass \n",
    "        loss.backward()\n",
    "        # UPDATE MODEL\n",
    "        optimizer.step()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        t3 = time.time()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # if batch_idx % 20 == 0:\n",
    "        #     print(\n",
    "        #         f\"Batch {batch_idx}: \"\n",
    "        #         f\"h2d={(t1-t0)*1000:.1f}ms | \"\n",
    "        #         f\"fwd+loss={(t2-t1)*1000:.1f}ms | \"\n",
    "        #         f\"bwd+step={(t3-t2)*1000:.1f}\"\n",
    "        #     )\n",
    "\n",
    "        # # Print progess \n",
    "        # if batch_idx % 10 == 0:\n",
    "        #     print(f\"Epoch {epoch} [{batch_idx}/{len(dataloader)}] Loss: {loss.item():.4f}\")\n",
    "        # t_batch_start = time.time()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "# Validation function \n",
    "\n",
    "def validate(\n",
    "    model: nn.Module, \n",
    "    dataloader: DataLoader, \n",
    "    criterion: nn.Module, \n",
    "    device: torch.device\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Validate the model\n",
    "\n",
    "    TODO: MODIFY to add more metrics (PSNR, SSIM, etc)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            rgb = batch['rgb'].to(device)\n",
    "            ground_truth = batch['ground_truth'].to(device)\n",
    "\n",
    "            # Optional: MASKED LOSS ***\n",
    "            mask = batch.get('border', None)\n",
    "            if mask is not None:\n",
    "                mask = mask.to(device)\n",
    "\n",
    "            output = model(rgb)\n",
    "\n",
    "            # Compute loss (standard or masked \n",
    "            if isinstance(criterion, (MaskedL1Loss, MaskedMSELoss)):\n",
    "                loss = criterion(output, ground_truth, mask)\n",
    "            elif isinstance(criterion, SSIMLoss):\n",
    "                loss = criterion(output, ground_truth)\n",
    "            elif isinstance(criterion, UVReconstructionLoss):\n",
    "                losses = criterion(pred_image=output, target_image=ground_truth, mask=mask)\n",
    "                loss = losses['total']\n",
    "            else:\n",
    "                loss = criterion(output, ground_truth)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368f2c8e-f271-43ab-bae7-762268d4b58b",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41ba305-0351-4b61-b3e4-75c4b9e7f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop \n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main training loop \n",
    "\n",
    "    *** CHECK TODO LIST ***\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configuration\n",
    "    DATA_DIR = '/home/daniel-choate/Datasets/DocUnwarp/renders/synthetic_data_pitch_sweep'\n",
    "    BATCH_SIZE = 8\n",
    "    NUM_EPOCHS = 50\n",
    "    LEARNING_RATE = 1e-4\n",
    "    IMG_SIZE = (256, 256) # (512, 512) Using smaller images for faster training for now\n",
    "\n",
    "    # Set device \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader, val_loader = get_dataloaders(\n",
    "        data_dir=DATA_DIR,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        img_size=IMG_SIZE,\n",
    "        use_depth=False, # TODO: True if using depth info\n",
    "        use_uv=False, # TODO: True if using UV maps\n",
    "        use_border=False # TODO: True if using border masks for better training\n",
    "    )\n",
    "\n",
    "    # Visualize a batch (testing)\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    print(f\"Batch RGB shape: {sample_batch['rgb'].shape}\")\n",
    "    print(f\"Batch GT shape: {sample_batch['ground_truth'].shape}\")\n",
    "    if 'border' in sample_batch:\n",
    "        print(f\"Batch border mask shape: {sample_batch['border'].shape}\")\n",
    "    # visualize_batch(sample_batch) # Troubleshooting / sanity check \n",
    "\n",
    "\n",
    "    # Create model\n",
    "    model = DocumentReconstructionModel().to(device)\n",
    "    print(f\"\\nModel parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "    # TODO: TRY DIFFERENT LOSS FUNCTIONS\n",
    "    # Option 1: simple losses (baseline, just to get it working)\n",
    "    # criterion = nn.MSELoss() # Basic L2 Loss - sensitive to lighting\n",
    "    # criterion = nn.L1Loss() # L1 loss also sensitive to lighting\n",
    "\n",
    "    # Option 2: SSIM loss (RECOMMENDED - structure instead of lighting)\n",
    "    criterion = SSIMLoss() # Might need a pip install\n",
    "\n",
    "    # Option 3: Masked losses (doc pixel focus)\n",
    "    # Make sure to do use_border = True above **\n",
    "    # criterion = MaskedL1Loss(use_mask=True)\n",
    "    # criterion = MaskedMSELoss(use_mask=True)\n",
    "\n",
    "    # Option 4: Combined loss with UV supervision (GET TO THIS EVENTUALLY)\n",
    "    # NOTE: need to set use_uv = True, use_border = True, \n",
    "    # criterion = UVReconstructionLoss(\n",
    "    #     reconstruction_weight=1.0,\n",
    "    #     uv_weight=0.5,\n",
    "    #     smoothness_weight=0.01, \n",
    "    #     use_mask=True,\n",
    "    #     loss_type='ssim' # Use SSIM for geometric recon\n",
    "    # )\n",
    "\n",
    "    # TODO: TRY DIFFERENT OPTIMIZERS\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    # optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "\n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # Epoch timing check\n",
    "        start_epoch = time.time()\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"EPOCH {epoch+1}/{NUM_EPOCHS}\")\n",
    "        print(f\"{'='*50}\")\n",
    "\n",
    "        # TRAIN \n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "        print(f\"Train loss: {train_loss:.4f}\")\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # VALIDATE \n",
    "        val_loss = validate(model, val_loader, criterion, device)\n",
    "        print(f\"Val Loss: {val_loss:.4f}\")\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Save the best model \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f\"Saved best model with val loss {val_loss}.4f\")\n",
    "\n",
    "        epoch_time = time.time() - start_epoch\n",
    "        print(f\"Epoch time: {epoch_time:.4f}s\")\n",
    "\n",
    "    print(\"\\nTraining complete!\")\n",
    "    print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cee6e9-4750-42eb-985b-db6e41b1bdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute main \n",
    "\n",
    "print(\"Document Reconstruction Dataset Loader\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Quick test \n",
    "train_loader, val_loader = get_dataloaders(\n",
    "    data_dir = '/home/daniel-choate/Datasets/DocUnwarp/renders/synthetic_data_pitch_sweep',\n",
    "    batch_size = 4, \n",
    "    img_size=(256, 256) # (512,512)\n",
    ")\n",
    "\n",
    "print(\"\\nDataset loaded successfully!\")\n",
    "\n",
    "# # Visualize sample batch \n",
    "# print(\"\\nVisualizing a sample batch ...\")\n",
    "# sample_batch = next(iter(train_loader))\n",
    "# print(f\"Batch shape - RGB: {sample_batch['rgb'].shape}, Ground Truth: {sample_batch['ground_truth'].shape}\")\n",
    "# visualize_batch(sample_batch, num_samples=min(4, sample_batch['rgb'].shape[0]))\n",
    "\n",
    "# Main training loop \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc8acc-ec19-4ef2-bfdd-67efee5dfc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute main \n",
    "\n",
    "print(\"Document Reconstruction Dataset Loader\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Quick test \n",
    "try: \n",
    "    train_loader, val_loader = get_dataloaders(\n",
    "        data_dir = '/home/daniel-choate/Datasets/DocUnwarp/renders/synthetic_data_pitch_sweep',\n",
    "        batch_size = 4, \n",
    "        img_size=(512, 512)\n",
    "    )\n",
    "\n",
    "    print(\"\\nDataset loaded successfully!\")\n",
    "\n",
    "    # # Visualize sample batch \n",
    "    # print(\"\\nVisualizing a sample batch ...\")\n",
    "    # sample_batch = next(iter(train_loader))\n",
    "    # print(f\"Batch shape - RGB: {sample_batch['rgb'].shape}, Ground Truth: {sample_batch['ground_truth'].shape}\")\n",
    "    # visualize_batch(sample_batch, num_samples=min(4, sample_batch['rgb'].shape[0]))\n",
    "\n",
    "    # Main training loop \n",
    "    main()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nError loading dataset: {e}\")\n",
    "    print(\"Check that data directory exists and contains required files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066e6e1-6104-47da-bbcb-fd7f67166c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6728a9b3-eab3-439d-ac7e-79e8efc56788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
